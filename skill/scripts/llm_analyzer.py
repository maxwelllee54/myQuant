#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LLMå¢å¼ºåˆ†ææ¨¡å—
æ”¯æŒAPIå’Œæµè§ˆå™¨è‡ªåŠ¨åŒ–ä¸¤ç§æ¨¡å¼
"""

import os
import sys
from typing import List, Dict, Optional

class LLMAnalyzer:
    """å¤§è¯­è¨€æ¨¡å‹åˆ†æå™¨"""
    
    def __init__(self, api_mode='auto'):
        """
        åˆå§‹åŒ–LLMåˆ†æå™¨
        
        Args:
            api_mode: 'api', 'browser', 'auto'
                - 'api': ä»…ä½¿ç”¨API
                - 'browser': ä»…ä½¿ç”¨æµè§ˆå™¨
                - 'auto': è‡ªåŠ¨é€‰æ‹©ï¼ˆä¼˜å…ˆAPIï¼Œå¤±è´¥æ—¶åˆ‡æ¢æµè§ˆå™¨ï¼‰
        """
        self.api_mode = api_mode
        self.gemini_api_key = os.environ.get('GEMINI_API_KEY')
        self.openai_api_key = os.environ.get('OPENAI_API_KEY')
    
    def analyze_stock_gemini_api(self, ticker: str, company_name: str, prompt: str) -> Optional[str]:
        """ä½¿ç”¨Gemini APIåˆ†æè‚¡ç¥¨"""
        if not self.gemini_api_key:
            print("âš ï¸  æœªæ‰¾åˆ°GEMINI_API_KEYç¯å¢ƒå˜é‡")
            return None
        
        try:
            from google import genai
            from google.genai import types
            
            client = genai.Client(api_key=self.gemini_api_key)
            
            response = client.models.generate_content(
                model='gemini-2.5-flash',
                contents=prompt,
                config=types.GenerateContentConfig(
                    temperature=0.7,
                    max_output_tokens=4096
                )
            )
            
            return response.text
            
        except Exception as e:
            print(f"âœ— Gemini APIè°ƒç”¨å¤±è´¥: {e}")
            return None
    
    def analyze_stock_openai_api(self, ticker: str, company_name: str, prompt: str) -> Optional[str]:
        """ä½¿ç”¨OpenAI APIåˆ†æè‚¡ç¥¨"""
        if not self.openai_api_key:
            print("âš ï¸  æœªæ‰¾åˆ°OPENAI_API_KEYç¯å¢ƒå˜é‡")
            return None
        
        try:
            from openai import OpenAI
            
            client = OpenAI(api_key=self.openai_api_key)
            
            response = client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½èµ„æ·±çš„æŠ•èµ„åˆ†æå¸ˆã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=4096
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            print(f"âœ— OpenAI APIè°ƒç”¨å¤±è´¥: {e}")
            return None
    
    def analyze_stock_browser(self, ticker: str, company_name: str, prompt: str, 
                            service: str = 'chatgpt') -> Optional[str]:
        """
        ä½¿ç”¨æµè§ˆå™¨è‡ªåŠ¨åŒ–åˆ†æè‚¡ç¥¨
        
        Args:
            service: 'chatgpt', 'claude', 'gemini'
        """
        print(f"âš ï¸  APIæ¨¡å¼å¤±è´¥ï¼Œåˆ‡æ¢åˆ°æµè§ˆå™¨è‡ªåŠ¨åŒ–æ¨¡å¼")
        print(f"ğŸ“Œ è¯·ç¡®ä¿æ‚¨å·²åœ¨æµè§ˆå™¨ä¸­ç™»å½• {service}")
        print(f"ğŸ“Œ å¦‚éœ€å¸®åŠ©ï¼Œå¯ä»¥æ‰‹åŠ¨æ¥ç®¡æµè§ˆå™¨å®Œæˆåˆ†æ")
        
        # è¿™é‡Œåº”è¯¥è°ƒç”¨æµè§ˆå™¨è‡ªåŠ¨åŒ–å·¥å…·
        # ç”±äºè¿™æ˜¯æ¡†æ¶ä»£ç ï¼Œå®é™…å®ç°éœ€è¦åœ¨è°ƒç”¨æ—¶å®Œæˆ
        
        return None
    
    def analyze_stock(self, ticker: str, company_name: str, prompt: str, 
                     models: List[str] = ['gemini', 'openai']) -> Dict[str, str]:
        """
        ä½¿ç”¨å¤šä¸ªLLMåˆ†æè‚¡ç¥¨
        
        Args:
            ticker: è‚¡ç¥¨ä»£ç 
            company_name: å…¬å¸åç§°
            prompt: åˆ†ææç¤ºè¯
            models: è¦ä½¿ç”¨çš„æ¨¡å‹åˆ—è¡¨
        
        Returns:
            Dict[model_name, analysis_result]
        """
        results = {}
        
        for model in models:
            print(f"\næ­£åœ¨ä½¿ç”¨ {model.upper()} åˆ†æ {ticker} ({company_name})...")
            
            if model == 'gemini':
                if self.api_mode in ['api', 'auto']:
                    result = self.analyze_stock_gemini_api(ticker, company_name, prompt)
                    if result:
                        results['gemini'] = result
                        print(f"âœ“ Geminiåˆ†æå®Œæˆ")
                        continue
                
                if self.api_mode in ['browser', 'auto']:
                    result = self.analyze_stock_browser(ticker, company_name, prompt, 'gemini')
                    if result:
                        results['gemini_browser'] = result
            
            elif model == 'openai':
                if self.api_mode in ['api', 'auto']:
                    result = self.analyze_stock_openai_api(ticker, company_name, prompt)
                    if result:
                        results['openai'] = result
                        print(f"âœ“ OpenAIåˆ†æå®Œæˆ")
                        continue
                
                if self.api_mode in ['browser', 'auto']:
                    result = self.analyze_stock_browser(ticker, company_name, prompt, 'chatgpt')
                    if result:
                        results['openai_browser'] = result
        
        return results

def main():
    """ç¤ºä¾‹ç”¨æ³•"""
    analyzer = LLMAnalyzer(api_mode='auto')
    
    prompt = """
    è¯·åˆ†æä»¥ä¸‹è‚¡ç¥¨çš„æŠ•èµ„ä»·å€¼ï¼š
    
    è‚¡ç¥¨ä»£ç : AAPL
    å…¬å¸åç§°: Apple Inc.
    
    è¯·ä»åŸºæœ¬é¢ã€ä¼°å€¼ã€å¢é•¿å‰æ™¯å’Œé£é™©å››ä¸ªç»´åº¦è¿›è¡Œåˆ†æã€‚
    """
    
    results = analyzer.analyze_stock('AAPL', 'Apple Inc.', prompt, models=['gemini'])
    
    for model, analysis in results.items():
        print(f"\n{'='*80}")
        print(f"{model.upper()} åˆ†æç»“æœ:")
        print(f"{'='*80}")
        print(analysis)

if __name__ == '__main__':
    main()
